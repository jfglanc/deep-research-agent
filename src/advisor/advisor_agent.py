## Research Advisor Agent

# This is a conversational agent with access to search to help define the research direction.
# It acts as a "research advisor" like a university professor would do.
# If the topic is well known, it will use its own knowledge to define the direction.
# If it's a new or niche topic, it will use search to help nail the scope using fresh context.

# It's a ReAct agent with a tool to trigger the main deep research supervisor.


from typing_extensions import Literal

from langchain_core.messages import AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.prebuilt import ToolNode

from src.advisor.tools import search_web, execute_research
from src.advisor.prompts import RESEARCH_ADVISOR_PROMPT
from src.config import get_advisor_model


# Models and tools

model = get_advisor_model()
model_with_tools = model.bind_tools([search_web, execute_research])


# ===== STATE =====

class ResearchAdvisorState(MessagesState):

    # If user approves, main graph will route to the research supervisor
    # Otherwise, the graph will end and user will continue discussing with the advisor
    user_approved: bool
    
    # Research topic and scope are generated by the advisor through user interaction
    research_topic: str
    research_scope: str



# ===== NODES =====

def call_model(state: ResearchAdvisorState):
    """
    Main ReAct node that decides whether to search, execute research, or continue conversation.
    """
    system_message = SystemMessage(content=RESEARCH_ADVISOR_PROMPT)
    messages = [system_message] + state["messages"]
    response = model_with_tools.invoke(messages)
    return {"messages": [response]}


# Tool node handles search_web and execute_research tools
tool_node = ToolNode(tools=[search_web, execute_research])


def save_research_brief(state: ResearchAdvisorState) -> dict:
    """Save research topic and scope when execute_research tool is called.
    
    Extracts the structured output from the execute_research tool call
    and saves it to state fields for the main graph to use.
    """
    # Look backwards to find the AI message with tool_calls
    for message in reversed(state["messages"]):
        if isinstance(message, AIMessage) and message.tool_calls:
            for tool_call in message.tool_calls:
                if tool_call["name"] == "execute_research":
                    args = tool_call["args"]
                    return {
                        "user_approved": True,
                        "research_topic": args["research_topic"],
                        "research_scope": args["research_scope"],
                        "messages": [AIMessage(content="I'm working on this deep research. I'll circle back with a full report in a couple of minutes!")]
                    }
    
    return {}


# ===== ROUTING LOGIC =====

def should_use_tools(state: ResearchAdvisorState) -> Literal["tool_node", "__end__"]:
    """Check if agent called tools and route to tool_node if true."""
    last_message = state["messages"][-1]
    
    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        return "tool_node"
    
    return END


def should_save_research_brief(state: ResearchAdvisorState) -> Literal["save_research_brief", "continue"]:
    """Check if execute_research tool was called and route appropriately."""
    for message in reversed(state["messages"]):
        if isinstance(message, AIMessage) and message.tool_calls:
            tool_names = [tc["name"] for tc in message.tool_calls]
            if "execute_research" in tool_names:
                return "save_research_brief"
            return "continue"
    return "continue"


# ===== GRAPH CONSTRUCTION =====

advisor_builder = StateGraph(ResearchAdvisorState)

# Add nodes
advisor_builder.add_node("call_model", call_model)
advisor_builder.add_node("tool_node", tool_node)
advisor_builder.add_node("save_research_brief", save_research_brief)

# Add edges
advisor_builder.add_edge(START, "call_model")

# If model calls tools, route to tool_node
advisor_builder.add_conditional_edges(
    "call_model",
    should_use_tools,
    {"tool_node": "tool_node", END: END}
)

# If execute_research tool is called, route to save_research_brief
advisor_builder.add_conditional_edges(
    "tool_node",
    should_save_research_brief,
    {
        "save_research_brief": "save_research_brief",
        "continue": "call_model"
    }
)

# Once research brief is saved, end the advisor graph
advisor_builder.add_edge("save_research_brief", END)

# Compile the advisor graph
advisor_agent = advisor_builder.compile()

